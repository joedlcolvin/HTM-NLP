{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring WordNet Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code demonstrates key features of WordNet. \n",
    "\n",
    "Reference: https://www.nltk.org/howto/wordnet.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import wordnet_ic as wic\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('bank.n.01'), Synset('depository_financial_institution.n.01'), Synset('bank.n.03'), Synset('bank.n.04'), Synset('bank.n.05'), Synset('bank.n.06'), Synset('bank.n.07'), Synset('savings_bank.n.02'), Synset('bank.n.09'), Synset('bank.n.10'), Synset('bank.v.01'), Synset('bank.v.02'), Synset('bank.v.03'), Synset('bank.v.04'), Synset('bank.v.05'), Synset('deposit.v.02'), Synset('bank.v.07'), Synset('trust.v.01')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Synset('flight_maneuver.n.01')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(wn.synsets('bank'))\n",
    "wn.synset('bank.n.10').hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('dog.n.01'), Synset('frump.n.01'), Synset('dog.n.03'), Synset('cad.n.01'), Synset('frank.n.02'), Synset('pawl.n.01'), Synset('andiron.n.01'), Synset('chase.v.01')]\n"
     ]
    }
   ],
   "source": [
    "# get synsets\n",
    "syns = wn.synsets('dog')\n",
    "print(syns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Lemma('dog.n.01.dog'), Lemma('frump.n.01.dog'), Lemma('dog.n.03.dog'), Lemma('cad.n.01.dog'), Lemma('frank.n.02.dog'), Lemma('pawl.n.01.dog'), Lemma('andiron.n.01.dog'), Lemma('chase.v.01.dog')]\n"
     ]
    }
   ],
   "source": [
    "# lemma of word\n",
    "lems = wn.lemmas('dog')\n",
    "print(lems)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog.n.01\n",
      "frump.n.01\n",
      "dog.n.03\n",
      "cad.n.01\n",
      "frank.n.02\n",
      "pawl.n.01\n",
      "andiron.n.01\n",
      "chase.v.01\n"
     ]
    }
   ],
   "source": [
    "# get synset name\n",
    "for syn in syns:\n",
    "    print(syn.name())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Lemma('dog.n.01.dog'), Lemma('dog.n.01.domestic_dog'), Lemma('dog.n.01.Canis_familiaris')]\n",
      "[Lemma('frump.n.01.frump'), Lemma('frump.n.01.dog')]\n",
      "[Lemma('dog.n.03.dog')]\n",
      "[Lemma('cad.n.01.cad'), Lemma('cad.n.01.bounder'), Lemma('cad.n.01.blackguard'), Lemma('cad.n.01.dog'), Lemma('cad.n.01.hound'), Lemma('cad.n.01.heel')]\n",
      "[Lemma('frank.n.02.frank'), Lemma('frank.n.02.frankfurter'), Lemma('frank.n.02.hotdog'), Lemma('frank.n.02.hot_dog'), Lemma('frank.n.02.dog'), Lemma('frank.n.02.wiener'), Lemma('frank.n.02.wienerwurst'), Lemma('frank.n.02.weenie')]\n",
      "[Lemma('pawl.n.01.pawl'), Lemma('pawl.n.01.detent'), Lemma('pawl.n.01.click'), Lemma('pawl.n.01.dog')]\n",
      "[Lemma('andiron.n.01.andiron'), Lemma('andiron.n.01.firedog'), Lemma('andiron.n.01.dog'), Lemma('andiron.n.01.dog-iron')]\n",
      "[Lemma('chase.v.01.chase'), Lemma('chase.v.01.chase_after'), Lemma('chase.v.01.trail'), Lemma('chase.v.01.tail'), Lemma('chase.v.01.tag'), Lemma('chase.v.01.give_chase'), Lemma('chase.v.01.dog'), Lemma('chase.v.01.go_after'), Lemma('chase.v.01.track')]\n"
     ]
    }
   ],
   "source": [
    "# lemma of synset\n",
    "for syn in syns:\n",
    "    print(syn.lemmas())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n",
      "domestic_dog\n",
      "Canis_familiaris\n",
      "frump\n",
      "dog\n",
      "dog\n",
      "cad\n",
      "bounder\n",
      "blackguard\n",
      "dog\n",
      "hound\n",
      "heel\n",
      "frank\n",
      "frankfurter\n",
      "hotdog\n",
      "hot_dog\n",
      "dog\n",
      "wiener\n",
      "wienerwurst\n",
      "weenie\n",
      "pawl\n",
      "detent\n",
      "click\n",
      "dog\n",
      "andiron\n",
      "firedog\n",
      "dog\n",
      "dog-iron\n",
      "chase\n",
      "chase_after\n",
      "trail\n",
      "tail\n",
      "tag\n",
      "give_chase\n",
      "dog\n",
      "go_after\n",
      "track\n"
     ]
    }
   ],
   "source": [
    "# lemma name\n",
    "for syn in syns:\n",
    "    lemmas = syn.lemmas()\n",
    "    for lemma in lemmas:\n",
    "        print(lemma.name())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Lemma('evil.n.03.evil')]\n"
     ]
    }
   ],
   "source": [
    "# antonyms of lemma\n",
    "lemmas = wn.synsets('good')[1].lemmas()\n",
    "lem = lemmas[0]\n",
    "print(lem.antonyms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Lemma('detect.v.01.observe'), Lemma('observe.v.08.observe')]\n"
     ]
    }
   ],
   "source": [
    "# derivations of lemma\n",
    "lemmas = wn.synsets('observation')[0].lemmas()\n",
    "lem = lemmas[0]\n",
    "print(lem.derivationally_related_forms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Lemma('sensing.n.02.perception')]\n"
     ]
    }
   ],
   "source": [
    "# pertainyms\n",
    "lemmas = wn.synsets('perceptual')[0].lemmas()\n",
    "lem = lemmas[0]\n",
    "print(lem.pertainyms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds\n",
      "a dull unattractive unpleasant girl or woman\n",
      "informal term for a man\n",
      "someone who is morally reprehensible\n",
      "a smooth-textured sausage of minced beef or pork usually smoked; often served on a bread roll\n",
      "a hinged catch that fits into a notch of a ratchet to move a wheel forward or prevent it from moving backward\n",
      "metal supports for logs in a fireplace\n",
      "go after with the intent to catch\n"
     ]
    }
   ],
   "source": [
    "# get definition of synset\n",
    "for syn in syns:\n",
    "    print(syn.definition())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the dog barked all night']\n",
      "['she got a reputation as a frump', \"she's a real dog\"]\n",
      "['you lucky dog']\n",
      "['you dirty dog']\n",
      "[]\n",
      "[]\n",
      "['the andirons were too hot to touch']\n",
      "['The policeman chased the mugger down the alley', 'the dog chased the rabbit']\n"
     ]
    }
   ],
   "source": [
    "# example of each synset\n",
    "for syn in syns:\n",
    "    print(syn.examples())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bounder', 'firedog', 'dog-iron', 'go_after', 'dog', 'andiron', 'click', 'tail', 'frankfurter', 'hot_dog', 'hotdog', 'wienerwurst', 'detent', 'chase_after', 'track', 'trail', 'frank', 'Canis_familiaris', 'tag', 'give_chase', 'domestic_dog', 'wiener', 'pawl', 'frump', 'weenie', 'cad', 'chase', 'blackguard', 'heel', 'hound'}\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "# get synonyms and antonyms\n",
    "synonyms = []\n",
    "antonyms = []\n",
    "\n",
    "for syn in syns:\n",
    "    for l in syn.lemmas():\n",
    "        synonyms.append(l.name())\n",
    "        if l.antonyms():\n",
    "            antonyms.append(l.antonyms()[0].name())\n",
    "\n",
    "print(set(synonyms))\n",
    "print(set(antonyms))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.631578947368421\n",
      "0.9285714285714286\n"
     ]
    }
   ],
   "source": [
    "# wup similarity\n",
    "w1 = wn.synset('dog.n.01')\n",
    "w2 = wn.synset('dog.n.03')\n",
    "print(w1.wup_similarity(w2))\n",
    "\n",
    "w1 = wn.synset('dog.n.01')\n",
    "w2 = wn.synset('domestic_dog.n.01')\n",
    "print(w1.wup_similarity(w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('canine.n.02'), Synset('domestic_animal.n.01')]\n",
      "[Synset('unpleasant_woman.n.01')]\n",
      "[Synset('chap.n.01')]\n",
      "[Synset('villain.n.01')]\n",
      "[Synset('sausage.n.01')]\n",
      "[Synset('catch.n.06')]\n",
      "[Synset('support.n.10')]\n",
      "[Synset('pursue.v.02')]\n"
     ]
    }
   ],
   "source": [
    "# hypernyms\n",
    "for syn in syns:\n",
    "    print(syn.hypernyms())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('basenji.n.01'), Synset('corgi.n.01'), Synset('cur.n.01'), Synset('dalmatian.n.02'), Synset('great_pyrenees.n.01'), Synset('griffon.n.02'), Synset('hunting_dog.n.01'), Synset('lapdog.n.01'), Synset('leonberg.n.01'), Synset('mexican_hairless.n.01'), Synset('newfoundland.n.01'), Synset('pooch.n.01'), Synset('poodle.n.01'), Synset('pug.n.01'), Synset('puppy.n.01'), Synset('spitz.n.01'), Synset('toy_dog.n.01'), Synset('working_dog.n.01')]\n",
      "[]\n",
      "[]\n",
      "[Synset('perisher.n.01')]\n",
      "[Synset('vienna_sausage.n.01')]\n",
      "[]\n",
      "[]\n",
      "[Synset('hound.v.01'), Synset('quest.v.02'), Synset('run_down.v.07'), Synset('tree.v.03')]\n"
     ]
    }
   ],
   "source": [
    "# hyponyms\n",
    "for syn in syns:\n",
    "    print(syn.hyponyms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('canis.n.01'), Synset('pack.n.06')]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# holonyms\n",
    "for syn in syns:\n",
    "    print(syn.member_holonyms())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('entity.n.01')]\n",
      "[Synset('entity.n.01')]\n",
      "[Synset('entity.n.01')]\n",
      "[Synset('entity.n.01')]\n",
      "[Synset('entity.n.01')]\n",
      "[Synset('entity.n.01')]\n",
      "[Synset('entity.n.01')]\n",
      "[Synset('travel.v.01')]\n"
     ]
    }
   ],
   "source": [
    "# root hypernyms\n",
    "for syn in syns:\n",
    "    print(syn.root_hypernyms())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('carnivore.n.01')]\n",
      "[Synset('organism.n.01')]\n",
      "[Synset('organism.n.01')]\n",
      "[Synset('organism.n.01')]\n",
      "[Synset('physical_entity.n.01')]\n",
      "[Synset('whole.n.02')]\n",
      "[Synset('whole.n.02')]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# find lowest common hypernym\n",
    "for syn in syns:\n",
    "    print(syn.lowest_common_hypernyms(wn.synset('cat.n.01')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n",
      "0.2\n"
     ]
    }
   ],
   "source": [
    "# word similarity using built-in similarity measure\n",
    "# path_similarity() returns a score denoting how similar \n",
    "# two word senses are, based on the shortest path \n",
    "# that connects the senses in the is-a (hypernym/hypnoym) taxonomy. \n",
    "dog = wn.synset('dog.n.01')\n",
    "cat = wn.synset('cat.n.01')\n",
    "print(dog.path_similarity(cat))\n",
    "# similarity is reciprocal\n",
    "print(cat.path_similarity(dog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1111111111111111\n",
      "1.4403615823901665\n",
      "0.1\n",
      "0.3333333333333333\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "entity = wn.synset('entity.n.01')\n",
    "poodle = wn.synset('poodle.n.01')\n",
    "Object = wn.synset('object.n.01')\n",
    "print(entity.path_similarity(dog))\n",
    "print(entity.lch_similarity(dog))\n",
    "print(entity.path_similarity(poodle))\n",
    "print(entity.path_similarity(Object))\n",
    "print(dog.path_similarity(poodle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0281482472922856\n"
     ]
    }
   ],
   "source": [
    "# Leacock-Chodorow Similarity: Return a score denoting how similar \n",
    "# two word senses are, based on the shortest path that connects \n",
    "# the senses (as above) and the maximum depth of the taxonomy \n",
    "# in which the senses occur. The relationship is given as \n",
    "# -log(p/2d) where p is the shortest path length and d the taxonomy depth.\n",
    "print(dog.lch_similarity(cat))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "# Wu-Palmer Similarity: Return a score denoting how similar two word \n",
    "# senses are, based on the depth of the two senses in the taxonomy \n",
    "# and that of their Least Common Subsumer (most specific ancestor node). \n",
    "print(dog.wup_similarity(cat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet_ic to\n",
      "[nltk_data]     /Users/qiweishao/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet_ic.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet_ic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information Content: Load an information content file \n",
    "# from the wordnet_ic corpus.\n",
    "\n",
    "# ic-brown.dat file lists every word existing in the \n",
    "# Brown corpus and their information content values \n",
    "# (which are associated with word frequencies)\n",
    "brown_ic = wic.ic('ic-brown.dat')\n",
    "semcor_ic = wic.ic('ic-semcor.dat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('genesis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package genesis to\n",
      "[nltk_data]     /Users/qiweishao/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/genesis.zip.\n"
     ]
    }
   ],
   "source": [
    "# Alternatively, we can create an information content dictionary \n",
    "# from a corpus (or anything that has a words() method).\n",
    "from nltk.corpus import genesis\n",
    "genesis_ic = wn.ic(genesis, False, 0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.911666509036577\n",
      "7.204023991374837\n"
     ]
    }
   ],
   "source": [
    "# Resnik Similarity: Return a score denoting how similar two word \n",
    "# senses are, based on the Information Content (IC) of the \n",
    "# Least Common Subsumer (most specific ancestor node). \n",
    "# Note that for any similarity measure that uses information content, \n",
    "# the result is dependent on the corpus used to generate \n",
    "# the information content and the specifics of how the information \n",
    "# content was created.\n",
    "print(dog.res_similarity(cat, brown_ic))\n",
    "print(dog.res_similarity(cat, genesis_ic))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4497755285516739\n",
      "0.28539390848096946\n"
     ]
    }
   ],
   "source": [
    "# Jiang-Conrath Similarity Return a score denoting how similar \n",
    "# two word senses are, based on the Information Content (IC) of \n",
    "# the Least Common Subsumer (most specific ancestor node) and \n",
    "# that of the two input Synsets. The relationship is given by \n",
    "# the equation 1 / (IC(s1) + IC(s2) - 2 * IC(lcs)).\n",
    "print(dog.jcn_similarity(cat, brown_ic))\n",
    "print(dog.jcn_similarity(cat, genesis_ic))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8863288628086228\n",
      "0.8043806652422293\n"
     ]
    }
   ],
   "source": [
    "# Lin Similarity: Return a score denoting how similar two word \n",
    "# senses are, based on the Information Content (IC) of the \n",
    "# Least Common Subsumer (most specific ancestor node) and that \n",
    "# of the two input Synsets. The relationship is given by \n",
    "# the equation 2 * IC(lcs) / (IC(s1) + IC(s2)).\n",
    "print(dog.lin_similarity(cat, semcor_ic))\n",
    "print(dog.lin_similarity(cat, genesis_ic))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('chase.v.01')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get synset by POS\n",
    "wn.synsets('dog', pos='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('entity.n.01') []\n",
      "Synset('physical_entity.n.01') [Synset('entity.n.01')]\n",
      "Synset('abstraction.n.06') [Synset('entity.n.01')]\n",
      "Synset('thing.n.12') [Synset('physical_entity.n.01')]\n",
      "Synset('object.n.01') [Synset('physical_entity.n.01')]\n"
     ]
    }
   ],
   "source": [
    "# examine hypernyms of noun synsets\n",
    "from itertools import islice\n",
    "for synset in islice(wn.all_synsets('n'), 5):\n",
    "     print(synset, synset.hypernyms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get\n",
      "[Synset('get.v.01'), Synset('become.v.01'), Synset('get.v.03'), Synset('receive.v.02'), Synset('arrive.v.01'), Synset('bring.v.04'), Synset('experience.v.03'), Synset('pay_back.v.02'), Synset('have.v.17'), Synset('induce.v.02'), Synset('get.v.11'), Synset('grow.v.08'), Synset('contract.v.04'), Synset('get.v.14'), Synset('make.v.02'), Synset('drive.v.11'), Synset('catch.v.18'), Synset('catch.v.07'), Synset('get.v.19'), Synset('get.v.20'), Synset('get.v.21'), Synset('get.v.22'), Synset('catch.v.21'), Synset('catch.v.22'), Synset('get.v.25'), Synset('scram.v.01'), Synset('get.v.27'), Synset('get.v.28'), Synset('get.v.29'), Synset('catch.v.24'), Synset('draw.v.15'), Synset('get.v.32'), Synset('perplex.v.01'), Synset('get_down.v.07'), Synset('suffer.v.02'), Synset('beget.v.01')]\n",
      "abacus\n"
     ]
    }
   ],
   "source": [
    "# get original form of inflections\n",
    "print(wn.morphy('got', wn.VERB))\n",
    "print(wn.synsets('got', wn.VERB))\n",
    "\n",
    "# Morphy can use inflection rules without user input of POS\n",
    "print(wn.morphy('abaci'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# synset closure\n",
    "dog = wn.synset('dog.n.01')\n",
    "hypo = lambda s: s.hyponyms()\n",
    "hyper = lambda s: s.hypernyms()\n",
    "print(list(dog.closure(hypo, depth=1)) == dog.hyponyms())\n",
    "print(list(dog.closure(hyper, depth=1)) == dog.hypernyms())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('basenji.n.01'), Synset('corgi.n.01'), Synset('cur.n.01'), Synset('dalmatian.n.02'), Synset('great_pyrenees.n.01'), Synset('griffon.n.02'), Synset('hunting_dog.n.01'), Synset('lapdog.n.01'), Synset('leonberg.n.01'), Synset('mexican_hairless.n.01'), Synset('newfoundland.n.01'), Synset('pooch.n.01'), Synset('poodle.n.01'), Synset('pug.n.01'), Synset('puppy.n.01'), Synset('spitz.n.01'), Synset('toy_dog.n.01'), Synset('working_dog.n.01'), Synset('cardigan.n.02'), Synset('pembroke.n.01'), Synset('feist.n.01'), Synset('pariah_dog.n.01'), Synset('liver-spotted_dalmatian.n.01'), Synset('brabancon_griffon.n.01'), Synset('courser.n.03'), Synset('dachshund.n.01'), Synset('hound.n.01'), Synset('rhodesian_ridgeback.n.01'), Synset('sporting_dog.n.01'), Synset('terrier.n.01'), Synset('large_poodle.n.01'), Synset('miniature_poodle.n.01'), Synset('standard_poodle.n.01'), Synset('toy_poodle.n.01'), Synset('chow.n.03'), Synset('keeshond.n.01'), Synset('pomeranian.n.01'), Synset('samoyed.n.03'), Synset('chihuahua.n.03'), Synset('japanese_spaniel.n.01'), Synset('maltese_dog.n.01'), Synset('pekinese.n.01'), Synset('shih-tzu.n.01'), Synset('toy_spaniel.n.01'), Synset('toy_terrier.n.01'), Synset('boxer.n.04'), Synset('bull_mastiff.n.01'), Synset('bulldog.n.01'), Synset('eskimo_dog.n.01'), Synset('great_dane.n.01'), Synset('guide_dog.n.01'), Synset('hearing_dog.n.01'), Synset('mastiff.n.01'), Synset('police_dog.n.01'), Synset('saint_bernard.n.01'), Synset('seizure-alert_dog.n.01'), Synset('sennenhunde.n.01'), Synset('shepherd_dog.n.01'), Synset('sled_dog.n.01'), Synset('watchdog.n.02'), Synset('sausage_dog.n.01'), Synset('afghan_hound.n.01'), Synset('basset.n.01'), Synset('beagle.n.01'), Synset('bloodhound.n.01'), Synset('bluetick.n.01'), Synset('boarhound.n.01'), Synset('coonhound.n.01'), Synset('foxhound.n.01'), Synset('greyhound.n.01'), Synset('harrier.n.02'), Synset('ibizan_hound.n.01'), Synset('norwegian_elkhound.n.01'), Synset('otterhound.n.01'), Synset('plott_hound.n.01'), Synset('redbone.n.01'), Synset('saluki.n.01'), Synset('scottish_deerhound.n.01'), Synset('staghound.n.01'), Synset('weimaraner.n.01'), Synset('wolfhound.n.01'), Synset('bird_dog.n.01'), Synset('griffon.n.03'), Synset('pointer.n.04'), Synset('retriever.n.01'), Synset('setter.n.02'), Synset('spaniel.n.01'), Synset('water_dog.n.02'), Synset('airedale.n.01'), Synset('australian_terrier.n.01'), Synset('bedlington_terrier.n.01'), Synset('border_terrier.n.01'), Synset('boston_bull.n.01'), Synset('bullterrier.n.01'), Synset('cairn.n.02'), Synset('dandie_dinmont.n.01'), Synset('fox_terrier.n.01'), Synset('irish_terrier.n.01'), Synset('kerry_blue_terrier.n.01'), Synset('lhasa.n.02'), Synset('norfolk_terrier.n.01'), Synset('norwich_terrier.n.01'), Synset('rat_terrier.n.01'), Synset('schnauzer.n.01'), Synset('scotch_terrier.n.01'), Synset('silky_terrier.n.01'), Synset('skye_terrier.n.01'), Synset('soft-coated_wheaten_terrier.n.01'), Synset('tibetan_terrier.n.01'), Synset('west_highland_white_terrier.n.01'), Synset('wirehair.n.01'), Synset('yorkshire_terrier.n.01'), Synset('english_toy_spaniel.n.01'), Synset('king_charles_spaniel.n.01'), Synset('papillon.n.01'), Synset('french_bulldog.n.01'), Synset('seeing_eye_dog.n.01'), Synset('tibetan_mastiff.n.01'), Synset('appenzeller.n.01'), Synset('bernese_mountain_dog.n.01'), Synset('entlebucher.n.01'), Synset('greater_swiss_mountain_dog.n.01'), Synset('belgian_sheepdog.n.01'), Synset('border_collie.n.01'), Synset('bouvier_des_flandres.n.01'), Synset('briard.n.01'), Synset('collie.n.01'), Synset('german_shepherd.n.01'), Synset('kelpie.n.02'), Synset('komondor.n.01'), Synset('old_english_sheepdog.n.01'), Synset('rottweiler.n.01'), Synset('shetland_sheepdog.n.01'), Synset('malamute.n.01'), Synset('siberian_husky.n.01'), Synset('attack_dog.n.01'), Synset('housedog.n.01'), Synset('kuvasz.n.01'), Synset('pinscher.n.01'), Synset('schipperke.n.01'), Synset('black-and-tan_coonhound.n.01'), Synset('coondog.n.01'), Synset('american_foxhound.n.01'), Synset('english_foxhound.n.01'), Synset('walker_hound.n.01'), Synset('italian_greyhound.n.01'), Synset('whippet.n.01'), Synset('borzoi.n.01'), Synset('irish_wolfhound.n.01'), Synset('german_short-haired_pointer.n.01'), Synset('vizsla.n.01'), Synset('chesapeake_bay_retriever.n.01'), Synset('curly-coated_retriever.n.01'), Synset('flat-coated_retriever.n.01'), Synset('golden_retriever.n.01'), Synset('labrador_retriever.n.01'), Synset('english_setter.n.01'), Synset('gordon_setter.n.01'), Synset('irish_setter.n.01'), Synset('brittany_spaniel.n.01'), Synset('clumber.n.01'), Synset('cocker_spaniel.n.01'), Synset('field_spaniel.n.01'), Synset('springer_spaniel.n.01'), Synset('sussex_spaniel.n.01'), Synset('water_spaniel.n.01'), Synset('american_staffordshire_terrier.n.01'), Synset('staffordshire_bullterrier.n.01'), Synset('smooth-haired_fox_terrier.n.01'), Synset('wire-haired_fox_terrier.n.01'), Synset('manchester_terrier.n.01'), Synset('giant_schnauzer.n.01'), Synset('miniature_schnauzer.n.01'), Synset('standard_schnauzer.n.01'), Synset('clydesdale_terrier.n.01'), Synset('lakeland_terrier.n.01'), Synset('welsh_terrier.n.01'), Synset('blenheim_spaniel.n.01'), Synset('groenendael.n.01'), Synset('malinois.n.01'), Synset('affenpinscher.n.01'), Synset('doberman.n.01'), Synset('miniature_pinscher.n.01'), Synset('english_springer.n.01'), Synset('welsh_springer_spaniel.n.01'), Synset('american_water_spaniel.n.01'), Synset('irish_water_spaniel.n.01'), Synset('toy_manchester.n.01'), Synset('sealyham_terrier.n.01')]\n"
     ]
    }
   ],
   "source": [
    "# all hyponyms\n",
    "print(list(dog.closure(hypo)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('canine.n.02'), Synset('domestic_animal.n.01'), Synset('carnivore.n.01'), Synset('animal.n.01'), Synset('placental.n.01'), Synset('organism.n.01'), Synset('mammal.n.01'), Synset('living_thing.n.01'), Synset('vertebrate.n.01'), Synset('whole.n.02'), Synset('chordate.n.01'), Synset('object.n.01'), Synset('physical_entity.n.01'), Synset('entity.n.01')]\n"
     ]
    }
   ],
   "source": [
    "# all hypernyms\n",
    "print(list(dog.closure(hyper)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# wup_similarity breaks when the two synsets have no common hypernym\n",
    "t = wn.synsets('titan')[1]\n",
    "s = wn.synsets('say', wn.VERB)[0]\n",
    "print(t.wup_similarity(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
