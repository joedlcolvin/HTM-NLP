{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring WordNet Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SDR: 2% of neurons are on at any point of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import wordnet_ic as wic\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate a tree into branches\n",
    "# returns the routes of tree along different branches\n",
    "def get_branches(tree):\n",
    "    return integrate_paths(branch_tree(tree))\n",
    "\n",
    "# branch a tree\n",
    "# returns a tree that shows where branches split up\n",
    "def branch_tree(tree):\n",
    "    flat_tree = []\n",
    "    if len(tree) <= 2:\n",
    "        for item in tree:\n",
    "            if type(item) != list:\n",
    "                flat_tree.append(item)\n",
    "            else:\n",
    "                flat_tree.extend(branch_tree(item))\n",
    "    else:\n",
    "        source = tree[0]\n",
    "        for i in range(1, len(tree)):\n",
    "            branch = [source]\n",
    "            branch.extend(branch_tree(tree[i]))\n",
    "            flat_tree.append(branch)\n",
    "    return flat_tree\n",
    "\n",
    "# join a branched tree into paths from root along each branch\n",
    "def integrate_paths(tree):\n",
    "    previous_nodes = []\n",
    "    all_paths = []\n",
    "    for item in tree:\n",
    "        if type(item) != list:\n",
    "            previous_nodes.append(item)\n",
    "        else:\n",
    "            nodes = previous_nodes.copy()\n",
    "            nodes.extend(item)\n",
    "            all_paths.append(nodes)\n",
    "    if not all_paths:\n",
    "        return previous_nodes\n",
    "    else:\n",
    "        return all_paths\n",
    "    \n",
    "\n",
    "\n",
    "# convert tree to sdr\n",
    "def tree_to_sdr(tree):\n",
    "    if len(tree) == 1:\n",
    "        return [[1]]\n",
    "    else:\n",
    "        sdr = []\n",
    "        for i in range(1, len(tree)):\n",
    "            dep = depth(tree)\n",
    "            path = []\n",
    "            for d in range(0, dep):\n",
    "                path.append([1])\n",
    "            sdr.append(path)\n",
    "        return sdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Synset('tiger.n.01'),\n",
       "  Synset('person.n.01'),\n",
       "  Synset('causal_agent.n.01'),\n",
       "  Synset('physical_entity.n.01'),\n",
       "  Synset('entity.n.01')],\n",
       " [Synset('tiger.n.01'),\n",
       "  Synset('person.n.01'),\n",
       "  Synset('organism.n.01'),\n",
       "  Synset('living_thing.n.01'),\n",
       "  Synset('whole.n.02'),\n",
       "  Synset('object.n.01'),\n",
       "  Synset('physical_entity.n.01'),\n",
       "  Synset('entity.n.01')]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize tree\n",
    "tree = wn.synset('tiger.n.01').tree(lambda s: s.hypernyms())\n",
    "# tree\n",
    "get_branches(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('bank.n.01'), Synset('depository_financial_institution.n.01'), Synset('bank.n.03'), Synset('bank.n.04'), Synset('bank.n.05'), Synset('bank.n.06'), Synset('bank.n.07'), Synset('savings_bank.n.02'), Synset('bank.n.09'), Synset('bank.n.10'), Synset('bank.v.01'), Synset('bank.v.02'), Synset('bank.v.03'), Synset('bank.v.04'), Synset('bank.v.05'), Synset('deposit.v.02'), Synset('bank.v.07'), Synset('trust.v.01')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Synset('flight_maneuver.n.01')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(wn.synsets('bank'))\n",
    "wn.synset('bank.n.10').hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('dog.n.01'), Synset('frump.n.01'), Synset('dog.n.03'), Synset('cad.n.01'), Synset('frank.n.02'), Synset('pawl.n.01'), Synset('andiron.n.01'), Synset('chase.v.01')]\n"
     ]
    }
   ],
   "source": [
    "# get synsets\n",
    "syns = wn.synsets('dog')\n",
    "print(syns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Lemma('dog.n.01.dog'), Lemma('frump.n.01.dog'), Lemma('dog.n.03.dog'), Lemma('cad.n.01.dog'), Lemma('frank.n.02.dog'), Lemma('pawl.n.01.dog'), Lemma('andiron.n.01.dog'), Lemma('chase.v.01.dog')]\n"
     ]
    }
   ],
   "source": [
    "# lemma of word\n",
    "lems = wn.lemmas('dog')\n",
    "print(lems)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog.n.01\n",
      "frump.n.01\n",
      "dog.n.03\n",
      "cad.n.01\n",
      "frank.n.02\n",
      "pawl.n.01\n",
      "andiron.n.01\n",
      "chase.v.01\n"
     ]
    }
   ],
   "source": [
    "# get synset name\n",
    "for syn in syns:\n",
    "    print(syn.name())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Lemma('dog.n.01.dog'), Lemma('dog.n.01.domestic_dog'), Lemma('dog.n.01.Canis_familiaris')]\n",
      "[Lemma('frump.n.01.frump'), Lemma('frump.n.01.dog')]\n",
      "[Lemma('dog.n.03.dog')]\n",
      "[Lemma('cad.n.01.cad'), Lemma('cad.n.01.bounder'), Lemma('cad.n.01.blackguard'), Lemma('cad.n.01.dog'), Lemma('cad.n.01.hound'), Lemma('cad.n.01.heel')]\n",
      "[Lemma('frank.n.02.frank'), Lemma('frank.n.02.frankfurter'), Lemma('frank.n.02.hotdog'), Lemma('frank.n.02.hot_dog'), Lemma('frank.n.02.dog'), Lemma('frank.n.02.wiener'), Lemma('frank.n.02.wienerwurst'), Lemma('frank.n.02.weenie')]\n",
      "[Lemma('pawl.n.01.pawl'), Lemma('pawl.n.01.detent'), Lemma('pawl.n.01.click'), Lemma('pawl.n.01.dog')]\n",
      "[Lemma('andiron.n.01.andiron'), Lemma('andiron.n.01.firedog'), Lemma('andiron.n.01.dog'), Lemma('andiron.n.01.dog-iron')]\n",
      "[Lemma('chase.v.01.chase'), Lemma('chase.v.01.chase_after'), Lemma('chase.v.01.trail'), Lemma('chase.v.01.tail'), Lemma('chase.v.01.tag'), Lemma('chase.v.01.give_chase'), Lemma('chase.v.01.dog'), Lemma('chase.v.01.go_after'), Lemma('chase.v.01.track')]\n"
     ]
    }
   ],
   "source": [
    "# lemma of synset\n",
    "for syn in syns:\n",
    "    print(syn.lemmas())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n",
      "domestic_dog\n",
      "Canis_familiaris\n",
      "frump\n",
      "dog\n",
      "dog\n",
      "cad\n",
      "bounder\n",
      "blackguard\n",
      "dog\n",
      "hound\n",
      "heel\n",
      "frank\n",
      "frankfurter\n",
      "hotdog\n",
      "hot_dog\n",
      "dog\n",
      "wiener\n",
      "wienerwurst\n",
      "weenie\n",
      "pawl\n",
      "detent\n",
      "click\n",
      "dog\n",
      "andiron\n",
      "firedog\n",
      "dog\n",
      "dog-iron\n",
      "chase\n",
      "chase_after\n",
      "trail\n",
      "tail\n",
      "tag\n",
      "give_chase\n",
      "dog\n",
      "go_after\n",
      "track\n"
     ]
    }
   ],
   "source": [
    "# lemma name\n",
    "for syn in syns:\n",
    "    lemmas = syn.lemmas()\n",
    "    for lemma in lemmas:\n",
    "        print(lemma.name())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Lemma('evil.n.03.evil')]\n"
     ]
    }
   ],
   "source": [
    "# antonyms of lemma\n",
    "lemmas = wn.synsets('good')[1].lemmas()\n",
    "lem = lemmas[0]\n",
    "print(lem.antonyms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Lemma('detect.v.01.observe'), Lemma('observe.v.08.observe')]\n"
     ]
    }
   ],
   "source": [
    "# derivations of lemma\n",
    "lemmas = wn.synsets('observation')[0].lemmas()\n",
    "lem = lemmas[0]\n",
    "print(lem.derivationally_related_forms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Lemma('sensing.n.02.perception')]\n"
     ]
    }
   ],
   "source": [
    "# pertainyms\n",
    "lemmas = wn.synsets('perceptual')[0].lemmas()\n",
    "lem = lemmas[0]\n",
    "print(lem.pertainyms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds\n",
      "a dull unattractive unpleasant girl or woman\n",
      "informal term for a man\n",
      "someone who is morally reprehensible\n",
      "a smooth-textured sausage of minced beef or pork usually smoked; often served on a bread roll\n",
      "a hinged catch that fits into a notch of a ratchet to move a wheel forward or prevent it from moving backward\n",
      "metal supports for logs in a fireplace\n",
      "go after with the intent to catch\n"
     ]
    }
   ],
   "source": [
    "# get definition of synset\n",
    "for syn in syns:\n",
    "    print(syn.definition())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the dog barked all night']\n",
      "['she got a reputation as a frump', \"she's a real dog\"]\n",
      "['you lucky dog']\n",
      "['you dirty dog']\n",
      "[]\n",
      "[]\n",
      "['the andirons were too hot to touch']\n",
      "['The policeman chased the mugger down the alley', 'the dog chased the rabbit']\n"
     ]
    }
   ],
   "source": [
    "# example of each synset\n",
    "for syn in syns:\n",
    "    print(syn.examples())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'trail', 'weenie', 'dog', 'dog-iron', 'frump', 'heel', 'wiener', 'click', 'hotdog', 'pawl', 'wienerwurst', 'hound', 'go_after', 'hot_dog', 'firedog', 'tail', 'frank', 'blackguard', 'domestic_dog', 'Canis_familiaris', 'detent', 'andiron', 'give_chase', 'chase_after', 'chase', 'bounder', 'cad', 'frankfurter', 'track', 'tag'}\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "# get synonyms and antonyms\n",
    "synonyms = []\n",
    "antonyms = []\n",
    "\n",
    "for syn in syns:\n",
    "    for l in syn.lemmas():\n",
    "        synonyms.append(l.name())\n",
    "        if l.antonyms():\n",
    "            antonyms.append(l.antonyms()[0].name())\n",
    "\n",
    "print(set(synonyms))\n",
    "print(set(antonyms))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.631578947368421\n",
      "0.631578947368421\n"
     ]
    }
   ],
   "source": [
    "# wup similarity\n",
    "w1 = wn.synset('dog.n.01')\n",
    "w2 = wn.synset('dog.n.03')\n",
    "print(w1.wup_similarity(w2))\n",
    "\n",
    "w1 = wn.synset('dog.n.01')\n",
    "w1 = wn.synset('domestic_dog.n.01')\n",
    "print(w1.wup_similarity(w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('canine.n.02'), Synset('domestic_animal.n.01')]\n",
      "[Synset('unpleasant_woman.n.01')]\n",
      "[Synset('chap.n.01')]\n",
      "[Synset('villain.n.01')]\n",
      "[Synset('sausage.n.01')]\n",
      "[Synset('catch.n.06')]\n",
      "[Synset('support.n.10')]\n",
      "[Synset('pursue.v.02')]\n"
     ]
    }
   ],
   "source": [
    "# hypernyms\n",
    "for syn in syns:\n",
    "    print(syn.hypernyms())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('basenji.n.01'), Synset('corgi.n.01'), Synset('cur.n.01'), Synset('dalmatian.n.02'), Synset('great_pyrenees.n.01'), Synset('griffon.n.02'), Synset('hunting_dog.n.01'), Synset('lapdog.n.01'), Synset('leonberg.n.01'), Synset('mexican_hairless.n.01'), Synset('newfoundland.n.01'), Synset('pooch.n.01'), Synset('poodle.n.01'), Synset('pug.n.01'), Synset('puppy.n.01'), Synset('spitz.n.01'), Synset('toy_dog.n.01'), Synset('working_dog.n.01')]\n",
      "[]\n",
      "[]\n",
      "[Synset('perisher.n.01')]\n",
      "[Synset('vienna_sausage.n.01')]\n",
      "[]\n",
      "[]\n",
      "[Synset('hound.v.01'), Synset('quest.v.02'), Synset('run_down.v.07'), Synset('tree.v.03')]\n"
     ]
    }
   ],
   "source": [
    "# hyponyms\n",
    "for syn in syns:\n",
    "    print(syn.hyponyms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('canis.n.01'), Synset('pack.n.06')]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# holonyms\n",
    "for syn in syns:\n",
    "    print(syn.member_holonyms())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('entity.n.01')]\n",
      "[Synset('entity.n.01')]\n",
      "[Synset('entity.n.01')]\n",
      "[Synset('entity.n.01')]\n",
      "[Synset('entity.n.01')]\n",
      "[Synset('entity.n.01')]\n",
      "[Synset('entity.n.01')]\n",
      "[Synset('travel.v.01')]\n"
     ]
    }
   ],
   "source": [
    "# root hypernyms\n",
    "for syn in syns:\n",
    "    print(syn.root_hypernyms())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('carnivore.n.01')]\n",
      "[Synset('organism.n.01')]\n",
      "[Synset('organism.n.01')]\n",
      "[Synset('organism.n.01')]\n",
      "[Synset('physical_entity.n.01')]\n",
      "[Synset('whole.n.02')]\n",
      "[Synset('whole.n.02')]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# find lowest common hypernym\n",
    "for syn in syns:\n",
    "    print(syn.lowest_common_hypernyms(wn.synset('cat.n.01')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n",
      "0.2\n"
     ]
    }
   ],
   "source": [
    "# word similarity using built-in similarity measure\n",
    "# path_similarity() returns a score denoting how similar \n",
    "# two word senses are, based on the shortest path \n",
    "# that connects the senses in the is-a (hypernym/hypnoym) taxonomy. \n",
    "dog = wn.synset('dog.n.01')\n",
    "cat = wn.synset('cat.n.01')\n",
    "print(dog.path_similarity(cat))\n",
    "# similarity is reciprocal\n",
    "print(cat.path_similarity(dog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0281482472922856\n"
     ]
    }
   ],
   "source": [
    "# Leacock-Chodorow Similarity: Return a score denoting how similar \n",
    "# two word senses are, based on the shortest path that connects \n",
    "# the senses (as above) and the maximum depth of the taxonomy \n",
    "# in which the senses occur. The relationship is given as \n",
    "# -log(p/2d) where p is the shortest path length and d the taxonomy depth.\n",
    "print(dog.lch_similarity(cat))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "# Wu-Palmer Similarity: Return a score denoting how similar two word \n",
    "# senses are, based on the depth of the two senses in the taxonomy \n",
    "# and that of their Least Common Subsumer (most specific ancestor node). \n",
    "print(dog.wup_similarity(cat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet_ic to\n",
      "[nltk_data]     /Users/qiweishao/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet_ic.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet_ic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information Content: Load an information content file \n",
    "# from the wordnet_ic corpus.\n",
    "\n",
    "# ic-brown.dat file lists every word existing in the \n",
    "# Brown corpus and their information content values \n",
    "# (which are associated with word frequencies)\n",
    "brown_ic = wic.ic('ic-brown.dat')\n",
    "semcor_ic = wic.ic('ic-semcor.dat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('genesis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package genesis to\n",
      "[nltk_data]     /Users/qiweishao/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/genesis.zip.\n"
     ]
    }
   ],
   "source": [
    "# Alternatively, we can create an information content dictionary \n",
    "# from a corpus (or anything that has a words() method).\n",
    "from nltk.corpus import genesis\n",
    "genesis_ic = wn.ic(genesis, False, 0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.911666509036577\n",
      "7.204023991374837\n"
     ]
    }
   ],
   "source": [
    "# Resnik Similarity: Return a score denoting how similar two word \n",
    "# senses are, based on the Information Content (IC) of the \n",
    "# Least Common Subsumer (most specific ancestor node). \n",
    "# Note that for any similarity measure that uses information content, \n",
    "# the result is dependent on the corpus used to generate \n",
    "# the information content and the specifics of how the information \n",
    "# content was created.\n",
    "print(dog.res_similarity(cat, brown_ic))\n",
    "print(dog.res_similarity(cat, genesis_ic))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4497755285516739\n",
      "0.28539390848096946\n"
     ]
    }
   ],
   "source": [
    "# Jiang-Conrath Similarity Return a score denoting how similar \n",
    "# two word senses are, based on the Information Content (IC) of \n",
    "# the Least Common Subsumer (most specific ancestor node) and \n",
    "# that of the two input Synsets. The relationship is given by \n",
    "# the equation 1 / (IC(s1) + IC(s2) - 2 * IC(lcs)).\n",
    "print(dog.jcn_similarity(cat, brown_ic))\n",
    "print(dog.jcn_similarity(cat, genesis_ic))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8863288628086228\n",
      "0.8043806652422293\n"
     ]
    }
   ],
   "source": [
    "# Lin Similarity: Return a score denoting how similar two word \n",
    "# senses are, based on the Information Content (IC) of the \n",
    "# Least Common Subsumer (most specific ancestor node) and that \n",
    "# of the two input Synsets. The relationship is given by \n",
    "# the equation 2 * IC(lcs) / (IC(s1) + IC(s2)).\n",
    "print(dog.lin_similarity(cat, semcor_ic))\n",
    "print(dog.lin_similarity(cat, genesis_ic))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
